---
title: "Weekend Homework - Model Building"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

# MVP

We've looked at a few different ways in which we can build models this week, including how to prepare them properly. This weekend we'll build a multiple linear regression model on a dataset which will need some preparation. The data can be found in the data folder, along with a data dictionary

We want to investigate the avocado dataset, and, in particular, to model the `AveragePrice` of the avocados. Use the tools we've worked with this week in order to prepare your dataset and find appropriate predictors. Once you've built your model use the validation techniques discussed on Wednesday to evaluate it. Feel free to focus either on building an *explanatory* or a *predictive* model, or both if you are feeling energetic!

As part of the MVP we want you not to just run the code but also have a go at **interpreting the results** and write your thinking in comments in your script.

**Hints and tips**

* `region` may lead to many dummy variables. Think carefully about whether to include this variable or not (there is no one 'right' answer to this!)
* Think about whether each variable is *categorical* or *numerical*. If categorical, make sure that the variable is represented as a factor.
* We will not treat this data as a time series, so `Date` will not be needed in your models, but can you extract any useful features out of `Date` before you discard it?
* If you want to build a predictive model, consider using either `leaps` or `glmulti` to help with this.


```{r}
library(tidyverse)
library(janitor)
library(ggplot2)
library(GGally)
library(modelr)
library(lubridate)
library(ggfortify)
```

```{r}
avocado_data <- read_csv("data/avocado.csv")
data_dictionary <- read_csv("data/data_dict.txt")
```

CLEAN NAMES
```{r}
avocado_data <- avocado_data %>% 
  janitor::clean_names()
```

LOOK FOR NAs (none) and non numeric variables (date, region, and type)
```{r}
summary(avocado_data)
glimpse(avocado_data)
```



Get month, or season(?) out of the date column - aware that
it is "quarter" (jan feb march)and not really "season":
```{r}
avocado_data <- avocado_data %>% 
  mutate(month = month(date, label = TRUE, abbr = FALSE),
         season = quarter(date))
```


Will I have too many regions to consider? (there are 54 - and I have no idea where
most of these places are in relation to each other - **REMEMBER THIS**)
```{r}
avocado_data %>% 
  distinct(region)
```

"Make categoricals into a factor". type (conventional or organic) region (54
regions...) 
(new cols: month is ordinal and season is integer - does that mean they are ok?):
```{r}
avocado_data <- avocado_data %>% 
  mutate(type = as_factor(type),
         region = as_factor(region),
         month = as_factor(month))
```


What can I get rid of?

`date`, and do I need the index (`x1`)? `total_bags` can come from the other bag 
sizes added (actually, wait to check alias for this...?)

```{r}
avocado_data_trimmed <- avocado_data %>% 
  select(-c(date, x1))
```

Check alias to see if anything else can go: 
```{r}
alias(average_price ~ ., data = avocado_data_trimmed)
```

Maybe get rid of `month`? It's probably too much too consider anyway. 
`total_bags` isn't an alias consideration as I thought...
```{r}
avocado_data_trimmed <- avocado_data_trimmed %>% 
  select(-month)

alias(average_price ~ ., data = avocado_data_trimmed)
```

So, back to region...: 
```{r}
avocado_data_trimmed %>% 
  ggplot()+
  aes(x = region,
      y = average_price)+
  geom_boxplot()
```

I think, seeing as I would not know how to bin the regions (do I need to?!) 
and as all (but 1?) median average prices are between 1 and 2 dollars, I will 
omit them for now. 
Maybe come back to this...


<hr>

### Model 1 consideration

```{r}
avo_data_trim_no_region <- avocado_data_trimmed %>% 
  select(-region)

avo_data_trim_no_region %>% 
  ggpairs()
```
oh... I can't see this. 

Everything with `average_price` looks to have at least 2 stars (ie. significant) 
I can't find a way to see this any bigger so...

```{r}
avo_data_trim_no_region %>% 
  summarise(cor(average_price, total_volume),
            cor(average_price, x4046),
            cor(average_price, x4225),
            cor(average_price, x4770),
            cor(average_price, total_bags),
            cor(average_price, small_bags),
            cor(average_price, large_bags),
            cor(average_price, x_large_bags),
           # cor(average_price, type),    type is not numeric
            cor(average_price, year),
            cor(average_price, season)
            )
```

I will consider (in order of highest correlation): 

1. `x4046` = -0.208
2. `total_volume` = -0.193
3. then lots of -0.17's so I will look at `season` (0.172) (`total_bags` (-0.177)
  has a higher sig but I'm already looking at total_volume)
4. and `type` as the overlap looks interesting


#### Model 1a. x4046 

Check diagnostics: 

```{r}
model1a <- lm(average_price ~ x4046, data = avo_data_trim_no_region)

autoplot(model1a) 
```

^ I do not like this 

* Residuals vs fitted: the line is mostly between 1 and -1 however the plots are
not randomly scattered around 0.
* Normal Q-Q: OK in the middle but strays from the line at the bototm and top.
Scale-Location: heteroscedastic (bad).
Residuals vs Leverage: 

```{r}
summary(model1a)
```

^ Though significant, when looking at Multiple R-squared, only 4% of the variance 
in average price is explained by variable x4046. 

#### Model 1b. total volume

Check diagnostics:
```{r}
model1b <- lm(average_price ~ total_volume, data = avo_data_trim_no_region)

autoplot(model1b)
```
Very similar to diagnostics for x4046

* Residuals vs fitted: the line is slightly better, between 1 and -1 however 
the plots are not randomly scattered around 0.
* Normal Q-Q: OK in the middle but strays from the line at the bototm and top.
Scale-Location: heteroscedastic (bad).
Residuals vs Leverage: 

```{r}
summary(model1b)
```

Again, though significant, even less of the variance is explained (3.7%)


#### Model 1c. season

Check diagnostics 
```{r}
model1c <- lm(average_price ~ season, data = avo_data_trim_no_region)

autoplot(model1c)
```

* Residuals vs fitted: relatively straight line around 0 is a positive result
* Normal Q-Q: deviation from the line at the bottom and top 
Scale-Location: 
Residuals vs Leverage:

```{r}
summary(model1c)
```
Significant, but only 2.9% of the variance is explained by season... shouldn't 
I be able to see the different "seasons"!? Let's change that (year 
as well?)!

```{r}
avo_data_trim_no_region <-  avo_data_trim_no_region %>% 
  mutate(season = as_factor(season), 
         year = as_factor(year))

model1c <- lm(average_price ~ season, data = avo_data_trim_no_region)

autoplot(model1c)

summary(model1c)
```
ok, now i can see them all but there is not much difference between them (e.g. 
only an increase in 0.07 on the average price in quarter("season")2 and 0.21 in 
season 3). The residuals are quite the same. 

#### Model 1d. type

```{r}
model1d <- lm(average_price ~ type, data = avo_data_trim_no_region)

autoplot(model1d)
```

* Residuals vs fitted: straight line at 0 is probably exactly what we want as the
 plots will be randomly scattered on either side. 
* Normal Q-Q: higher values stray from the line but otherwise looking OK.
* Scale-Location: 
* Residuals vs Leverage:

```{r}
summary(model1d)
```
Organic or conventional is significant and accounts for 38% of the variance in 
average price. This is by far the best so far (the others lay around 3 or 4%)
and so we will go ahead with model 1d.


### Model 2 consideration 

Going ahead with model1d (type). Running ggpairs with the residuals:

```{r}
avo_residuals <- avo_data_trim_no_region %>% 
  add_residuals(model1d) %>% 
  select(-c(average_price, type))

avo_residuals %>% 
  ggpairs()
```
can't see so well again but :
(season and year figures were from when I didn't realise they were not factors, 
so I will go ahead with them)

* `season` = 0.219 
* `year` = 0.118
* `x4046` = 0.88
* `large_bags` = 0.069

#### Model 2a. season

Residuals:
```{r}
model2a <- lm(average_price ~ type + season, data = avo_data_trim_no_region)

autoplot(model2a)
```
Normal Q-Q is straying from the line with higher values but otherwise I think 
it looks good. Maybe a little heteroskedacity in the scale-location (?)
```{r}
summary(model2a)
```
With all levels significant, 42% of the variance is explained by type and season. 
Though there is still not much of a difference in average price between seasons.



#### Model 2b. year

```{r}
model2b <- lm(average_price ~ type + year, data = avo_data_trim_no_region)

autoplot(model2b)
```

```{r}
summary(model2b)
```
In 2016 and 2018, the average price was less than it was in 2015 (intercept) but 
it was higher in 2017 (where type is constant(?)). 
These are very small (but significant) value changes though. 

This model accounts for 41% of the variance, with a very similar residual 
standard error (0.308) as that of model2a (season) (0.307).


#### Model 2c. x4046
```{r}
model2c <- lm(average_price ~ type + x4046, data = avo_data_trim_no_region)

autoplot(model2c)
```

I am honestly not sure how to interpret this ^ 
```{r}
summary(model2c)
```

A smaller multiple r-squared value (38% of variance explained), smaller 
adjusted r squared (0.38), and larger residual standard error lead me to prefer 
the above two models. 



#### Model 2d. large_bags 
```{r}
model2d <- lm(average_price ~ type + large_bags, data = avo_data_trim_no_region)

autoplot(model2d)
```

```{r}
summary(model2d)
```
As with x4046, a smaller multiple r-squared and adjusted r-squared and a larger
residual standard error lead me to prefering the other two models. 


**From Model 2** model2a ("type + season") will go ahead. 


### Model 3 consideration 

Going ahead with model2a (type + season). 

Running ggpairs with the residuals:

```{r}
avo_residuals_2 <- avo_data_trim_no_region %>% 
  add_residuals(model2a) %>% 
  select(-c(average_price, type, season))

avo_residuals_2 %>% 
  ggpairs()
```

As `year` was very close in the last group of models, I want to look into that 
again. But also: 

`x4046` = -0.085
`large_bag` = -0.064
`total_volume` = -0.060

#### Model 3a. type + season + year

```{r}
model3a <- lm(average_price ~ type + season + year, 
              data = avo_data_trim_no_region)

autoplot(model3a)
```
```{r}
summary(model3a)
```
Everything is significant, 45% of variance is explained by this model and we 
have a lower residual standard error than we did with just type + season. So 
that is good news. 

#### model 3b, type + season + x4046
```{r}
model3b <- lm(average_price ~ type + season + x4046, 
              data = avo_data_trim_no_region)

autoplot(model3b)
```

```{r}
summary(model3b)
```
Smaller multiple r squared and adjusted r squared, plus a larger residual 
standard error means that model 3a was better. 



#### Model 3c. type + season + large_bags

```{r}
model3c <- lm(average_price ~ type + season + large_bags, 
              data = avo_data_trim_no_region)

autoplot(model3c)
```

```{r}
summary(model3c)
```

Similar residual standard error to model3a but lower r-squared values. 


#### Model 3d. type + season + total_volume

```{r}
model3d <- lm(average_price ~ type + season + total_volume, 
              data = avo_data_trim_no_region)

autoplot(model3d)
```

```{r}
summary(model3d)
```
still not quite as good as 3a but it's pretty close. 


**average_price ~ type + season + year**
Model 3a will be chosen as it has the highest multiple r-squared (0.45) and 
adjusted r-squared (0.42)values as well as the lowest residual se (0.298).


### Model 4 consideration 

Running ggpairs with the residuals:

```{r}
avo_residuals_3 <- avo_data_trim_no_region %>% 
  add_residuals(model3a) %>% 
  select(-c(average_price, type, season, year))

avo_residuals_3 %>% 
  ggpairs()
```


`x4046` = -0.089
`large_bags` = -0.077
`total_volume` = 0.063

#### Model 4a. type, season, year, x4044

```{r}
model4a <- lm(average_price ~ type + season + year + x4046, 
              data = avo_data_trim_no_region)

autoplot(model4a)
```
Looking better but still heteroskedastic in scale-location
```{r}
summary(model4a)
```

All significant. Lower than other residual standard errors = 0.297. 45.8% of 
variance accounted for by this model and the adjusted r-sqaured is looking good 
too. 



#### Model 4b. type, season, year, large_bags

```{r}
model4b <- lm(average_price ~ type + season + year + large_bags, 
              data = avo_data_trim_no_region)

autoplot(model4b)
```

```{r}
summary(model4b)
```
45.7% variance (model 4a is 45.8), smaller adjusted r-squared than model 4a (only 
by 0.0012), and same residual standard error. 

#### Model 4c. type, season, year, total_volume

```{r}
model4c <- lm(average_price ~ type + season + year + total_volume, 
              data = avo_data_trim_no_region)

autoplot(model4c)
```

```{r}
summary(model4c)
```
The lowest, but only just, variance accounted for at 45.6% (model4a = 45.8% and 
model 4b = 45.7%) but has the same adjusted r-squared (0.46) so they are all very 
similar. Residual standard error (0.297) is also the same as the other two models.


I guess you go with `model4a` as it has the highest multiple r-squared (by 0.1%)
**average price ~ type, season, year, x4046**






**One more? There hasn't been much of a change since model 3a so maybe I should**
**have stopped there?**

### Model 5 consideration

Running ggpairs with the residuals:

```{r}
avo_residuals_4 <- avo_data_trim_no_region %>% 
  add_residuals(model3a) %>% 
  select(-c(average_price, type, season, year, x4046))

avo_residuals_4 %>% 
  ggpairs()
```
`large_bags` and `total_volume`

#### model 5a. type, season, year, x4044, large_bags

```{r}
model5a <- lm(average_price ~ type + season + year + x4046 + large_bags, 
              data = avo_data_trim_no_region)

autoplot(model5a)
```


```{r}
summary(model5a)
```
Large bags is not significant. Try an ANOVA:

```{r}
anova(model4a, model5a)
```

Large_bags is not significant p = 0.47 (we want it to be < 0.05) 



#### model 5b. type, season, year, x4044, total_volume

```{r}
model5b <- lm(average_price ~ type + season + year + x4046 + total_volume, 
              data = avo_data_trim_no_region)

autoplot(model5b)
```


```{r}
summary(model5b)
```

Ah, a change in r-squared, now 47% of the variance is accounted for by this
model (5b = average_price ~ type + season + year + x4046 + total_volume) with 
a residual standar error similar to what we have seen in other models (0.29).

So I think we will stop with **model5b:** 
**average_price ~ type + season + year + x4046 + total_volume**


### Interactions? 

```{r}
average_price_residuals <- avo_data_trim_no_region %>% 
  add_residuals(model5b) %>% 
  select(-average_price)
```


```{r}
coplot(resid ~ type | season, 
       panel = function(x, y, ...){
         points(x, y)
         abline(lm(y ~ x), col = "blue")},
       data = average_price_residuals, 
       columns = 4)
```
^ not really any interaction


```{r}
coplot(resid ~ type | year, 
       panel = function(x, y, ...){
         points(x, y)
         abline(lm(y ~ x), col = "blue")},
       data = average_price_residuals, 
       columns = 4)
```
^ small interaction 

```{r}
coplot(resid ~ type | x4046, 
       panel = function(x, y, ...){
         points(x, y)
         abline(lm(y ~ x), col = "blue")},
       data = average_price_residuals, 
       columns = 4)
```
^ nope

```{r}
coplot(resid ~ type | total_volume, 
       panel = function(x, y, ...){
         points(x, y)
         abline(lm(y ~ x), col = "blue")},
       data = average_price_residuals, 
       columns = 6)
```



```{r}
coplot(resid ~ year | season, 
       panel = function(x, y, ...){
         points(x, y)
         abline(lm(y ~ x), col = "blue")},
       data = average_price_residuals, 
       columns = 4)
```
^ this is interesting

mod4a <- lm(prestige ~ education + income + type + education:income, data = prestige_trim)
summary(mod4a)
```{r}
model_interaction <- lm(average_price ~ season + year + x4046 + total_volume +
                          season:year, data = avo_data_trim_no_region)

autoplot(model_interaction)
summary(model_interaction)
```

Lots of insignificants and very heteroskedastic plots!
```{r}
anova(model5b, model_interaction)
```


I would choose to go stick with **model5b:** 
**average_price ~ type + season + year + x4046 + total_volume**